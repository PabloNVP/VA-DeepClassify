# Archivo de configuración para el proyecto de clasificación de imágenes

[directories]
# Carpeta donde se encuentran las imágenes originales organizadas en subcarpetas por clase.
# Ejemplo: ./images/clase1/, ./images/clase2/, etc.
# Esta carpeta se usa como entrada para el script de división del dataset.
source_dir = ./images

# Carpeta base donde se guardarán las imágenes divididas en train/val/test.
# Se crearán automáticamente las subcarpetas necesarias.
data_dir = ./data

# Carpeta con imágenes para entrenamiento del modelo.
# El modelo aprende los patrones de estas imágenes.
train_dir = ./data/train

# Carpeta con imágenes para validación durante el entrenamiento.
# Se usa para monitorear el rendimiento y evitar sobreajuste.
val_dir = ./data/val

# Carpeta con imágenes para prueba final del modelo.
# Solo se usa al final para evaluar el rendimiento real (datos nunca vistos).
test_dir = ./data/test

# Carpeta donde se guardarán los modelos entrenados.
# Los archivos se nombran automáticamente según la arquitectura usada.
model_save_dir = ./models

[dataset_split]
# Porcentaje de imágenes destinadas al entrenamiento (70% = 0.7).
# Estas imágenes son las que el modelo usará para aprender.
# Recomendado: 0.7-0.8 para datasets grandes, 0.6-0.7 para datasets pequeños.
train_split = 0.7

# Porcentaje de imágenes destinadas a validación (20% = 0.2).
# Se usan durante el entrenamiento para verificar que el modelo generaliza bien.
# Recomendado: 0.1-0.2
val_split = 0.2

# Porcentaje de imágenes destinadas a prueba final (10% = 0.1).
# Solo se usan al final para medir el rendimiento real del modelo.
# Recomendado: 0.1-0.2
# NOTA: train_split + val_split + test_split debe sumar 1.0
test_split = 0.1

[model]
# Ancho en píxeles al que se redimensionarán todas las imágenes de entrada.
# Debe coincidir con el tamaño esperado por la arquitectura elegida.
# EfficientNet, MobileNet, ResNet, DenseNet: 224 píxeles.
img_width = 224

# Alto en píxeles al que se redimensionarán todas las imágenes de entrada.
# Generalmente igual al ancho para imágenes cuadradas.
img_height = 224

# Número de categorías/clases diferentes que el modelo debe aprender a distinguir.
# Debe coincidir con la cantidad de subcarpetas en tu directorio de imágenes.
# Ejemplo: si tienes 6 tipos de cortes de carne, num_classes = 6
num_classes = 6

# Arquitectura de red neuronal preentrenada a utilizar (transfer learning).
# Opciones disponibles:
#   - efficientnet: Buen balance entre precisión y velocidad. Recomendado para empezar.
#   - mobilenet: Más liviano y rápido, ideal para dispositivos con recursos limitados.
#   - resnet: Arquitectura clásica, muy estudiada y robusta.
#   - densenet: Buena generalización, útil cuando hay pocos datos de entrenamiento.
architecture = efficientnet

[training]
# Cantidad de imágenes procesadas simultáneamente en cada paso de entrenamiento.
# Valores más altos = mayor uso de memoria GPU pero entrenamiento más rápido.
# Recomendado: 4-8 para GPUs con poca memoria, 16-32 para GPUs potentes.
batch_size = 4

# Número de veces que el modelo verá todo el dataset durante el entrenamiento.
# Más épocas puede mejorar la precisión, pero riesgo de sobreajuste (overfitting).
# Recomendado: 10-50 dependiendo del tamaño del dataset.
epochs = 10

# Velocidad con la que el modelo ajusta sus pesos durante el entrenamiento.
# Valores muy altos = aprendizaje inestable. Valores muy bajos = aprendizaje lento.
# Recomendado: 0.001 para empezar, reducir si el entrenamiento es inestable.
learning_rate = 0.001

[architecture]
# Número de neuronas en la capa densa antes de la clasificación final.
# Más unidades = mayor capacidad de aprendizaje pero más riesgo de sobreajuste.
# Recomendado: 64-256 dependiendo de la complejidad del problema.
dense_units = 128

# Porcentaje de neuronas desactivadas aleatoriamente durante el entrenamiento.
# Ayuda a prevenir el sobreajuste. Valor entre 0.0 (sin dropout) y 1.0 (todo desactivado).
# Recomendado: 0.3-0.5 para datasets pequeños, 0.1-0.3 para datasets grandes.
dropout_rate = 0.5
